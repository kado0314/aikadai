import streamlit as st
from diffusers import StableDiffusionPipeline
import torch
import random
import os
from PIL import Image
import cv2
import mediapipe as mp
import numpy as np
import math
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

# è§’åº¦ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
def calc_angle(a, b, c):
    """3ã¤ã®ç‚¹ã‹ã‚‰è§’åº¦ã‚’è¨ˆç®—ã™ã‚‹"""
    ba = [a[0] - b[0], a[1] - b[1]]
    bc = [c[0] - b[0], c[1] - b[1]]
    dot = ba[0]*bc[0] + ba[1]*bc[1]
    norm_ba = math.sqrt(ba[0]**2 + ba[1]**2)
    norm_bc = math.sqrt(bc[0]**2 + bc[1]**2)
    # ã‚¼ãƒ­é™¤ç®—ã‚’é˜²ããŸã‚ã®å°ã•ãªå€¤ã‚’è¿½åŠ 
    cos_angle = dot / (norm_ba * norm_bc + 1e-6)
    # acosã®å¼•æ•°ãŒ-1.0ã‹ã‚‰1.0ã®ç¯„å›²ã«åã¾ã‚‹ã‚ˆã†ã«ã‚¯ãƒªãƒƒãƒ—
    angle = math.degrees(math.acos(min(1.0, max(-1.0, cos_angle))))
    return angle

# MediaPipe Handsãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹é–¢æ•°
@st.cache_resource(show_spinner=False)
def mediapipe_reset():
    """MediaPipe Handsãƒ¢ãƒ‡ãƒ«ã¨æç”»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’åˆæœŸåŒ–ã™ã‚‹"""
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    # é™æ­¢ç”»ãƒ¢ãƒ¼ãƒ‰ã§Handsãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ï¼ˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¯è¡Œã‚ãªã„ï¼‰
    hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)
    return mp_hands, mp_drawing, hands

# Streamlitã®ã‚«ãƒ¡ãƒ©å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
def camera_input(label):
    """Streamlitã®ã‚«ãƒ¡ãƒ©å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’è¿”ã™"""
    return st.camera_input(label)

# MediaPipeã§æŒ‡ã®æ•°ã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
def mediapipe_prosess(uploaded_file, mp_hands, mp_drawing, hands):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‹ã‚‰MediaPipeã‚’ä½¿ã£ã¦æŒ‡ã®æ•°ã‚’æ¤œå‡ºã—ã€æç”»ã™ã‚‹ã€‚
    è¦ªæŒ‡ã¨ä»–ã®æŒ‡ã®æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ã‚’å«ã‚€ã€‚
    """
    if uploaded_file is not None:
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒˆé…åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã¿ã€OpenCVã§ãƒ‡ã‚³ãƒ¼ãƒ‰
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, 1)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # MediaPipeã§æ‰‹ã‚’å‡¦ç†
        results = hands.process(img_rgb)

        total_finger_count = 0
        annotated_img = img.copy() # æç”»ç”¨ã«ç”»åƒã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ

        if results.multi_hand_landmarks:
            for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                # æ¤œå‡ºã•ã‚ŒãŸæ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»
                mp_drawing.draw_landmarks(
                    annotated_img,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2), # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®è‰²
                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2) # æ¥ç¶šã®è‰²
                )

                landmarks = []
                h, w, c = img.shape
                for id, lm in enumerate(hand_landmarks.landmark):
                    # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®åº§æ¨™ã‚’ç”»åƒãƒ”ã‚¯ã‚»ãƒ«ã«å¤‰æ›
                    cx, cy = int(lm.x * w), int(lm.y * h)
                    landmarks.append([id, cx, cy])

                if landmarks:
                    fingers = 0
                    
                    # è¦ªæŒ‡ã®æ¤œå‡º
                    # è¦ªæŒ‡ã®ä»˜ã‘æ ¹(MCP)ã€ä¸­é–“é–¢ç¯€(IP)ã€å…ˆç«¯(TIP)ã®åº§æ¨™ã‚’å–å¾—
                    mcp = landmarks[mp_hands.HandLandmark.THUMB_MCP][1:3]
                    ip  = landmarks[mp_hands.HandLandmark.THUMB_IP][1:3]
                    tip = landmarks[mp_hands.HandLandmark.THUMB_TIP][1:3]
                    
                    # è¦ªæŒ‡ã®é–¢ç¯€è§’åº¦ã‚’è¨ˆç®—
                    thumb_angle = calc_angle(mcp, ip, tip)
                    
                    # è§’åº¦ãŒä¸€å®šä»¥ä¸Šã§ã‚ã‚Œã°è¦ªæŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ã¨åˆ¤æ–­
                    if thumb_angle > 160: # ã“ã®é–¾å€¤ã¯èª¿æ•´ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“
                        fingers += 1

                    # äººå·®ã—æŒ‡ã‹ã‚‰å°æŒ‡ã¾ã§ã®æ¤œå‡º (æŒ‡ã®å…ˆç«¯ãŒPIPé–¢ç¯€ã‚ˆã‚Šä¸Šã«ã‚ã‚‹ã‹ã§åˆ¤æ–­)
                    if landmarks[mp_hands.HandLandmark.INDEX_FINGER_TIP][2] < landmarks[mp_hands.HandLandmark.INDEX_FINGER_PIP][2]:
                        fingers += 1
                    if landmarks[mp_hands.HandLandmark.MIDDLE_FINGER_TIP][2] < landmarks[mp_hands.HandLandmark.MIDDLE_FINGER_PIP][2]:
                        fingers += 1
                    if landmarks[mp_hands.HandLandmark.RING_FINGER_TIP][2] < landmarks[mp_hands.HandLandmark.RING_FINGER_PIP][2]:
                        fingers += 1
                    if landmarks[mp_hands.HandLandmark.PINKY_TIP][2] < landmarks[mp_hands.HandLandmark.PINKY_PIP][2]:
                        fingers += 1

                    total_finger_count += fingers
        
        # å‡¦ç†ã•ã‚ŒãŸç”»åƒã‚’è¡¨ç¤º
        st.image(annotated_img, caption="æ¤œå‡ºçµæœ", channels="BGR", use_container_width=True)
        return total_finger_count
    else:
        return 0

# ã‚«ãƒ¡ãƒ©å…¥åŠ›ã¨æŒ‡ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã¾ã¨ã‚ãŸé–¢æ•°
def camera():
    """ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®å…¥åŠ›ã§æŒ‡ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã€çµæœã‚’è¡¨ç¤ºã™ã‚‹"""
    mp_hands, mp_drawing, hands = mediapipe_reset()
    uploaded_file = camera_input("ğŸ“¸ æŒ‡ã®æœ¬æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹å†™çœŸã‚’æ’®ã£ã¦ãã ã•ã„")
    if uploaded_file is not None:
        total_finger_count = mediapipe_prosess(uploaded_file, mp_hands, mp_drawing, hands)
        if total_finger_count > 0:
            st.success(f"ç”»åƒå†…ã§**{total_finger_count}æœ¬**ã®æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ã¨æ¤œå‡ºã—ã¾ã—ãŸï¼")
            if st.button("âœ… ã“ã®çµæœã§æ¬¡ã¸é€²ã‚€"):
                return total_finger_count
        else:
            st.warning("ä¼¸ã³ã¦ã„ã‚‹æŒ‡ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„ã€‚")
    return None

# ã‚²ãƒ¼ãƒ ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def reset_game_state():
    """ã‚²ãƒ¼ãƒ ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹"""
    keys_to_reset = [
        "v001_fruit", "v001_num", "v001_image_path", "v001_detected_count",
        "v001_generated", "v001_result_shown", "v001_camera1_count", "v001_camera2_count",
        "v001_guess", "v001_photo1_taken", "v001_photo2_taken", "v001_answer_checked",
        "last_result_message", "last_result_type", "last_actual_num_message",
        "fruit", "num", "image_path", "generated", "result_shown", "guess",
        "quiz_greeting", "quiz_answered" # æ‰‹è©±ãƒ¢ãƒ¼ãƒ‰ã®ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚ãƒªã‚»ãƒƒãƒˆ
    ]
    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]
    # é€£ç¶šæ­£è§£è¨˜éŒ²ã¯ãƒªã‚»ãƒƒãƒˆã—ãªã„ï¼ˆã‚²ãƒ¼ãƒ å…¨ä½“ã®ãƒªã‚»ãƒƒãƒˆã§ã¯ãªã„ãŸã‚ï¼‰
    # if "v001_consecutive_streak" in st.session_state:
    #     del st.session_state["v001_consecutive_streak"]


# ã‚«ãƒ¡ãƒ©å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆï¼ˆã‚­ãƒ¼ä»˜ãï¼‰
def camera_input_widget(label, key):
    """ã‚­ãƒ¼ä»˜ãã®Streamlitã‚«ãƒ¡ãƒ©å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’è¿”ã™"""
    return st.camera_input(label, key=key)

# --- ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿é–¢æ•° ---

device = "cuda" if torch.cuda.is_available() else "cpu"

@st.cache_resource(show_spinner=False)
def load_diffusion_model():
    """Stable Diffusionãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    pipe = StableDiffusionPipeline.from_pretrained(
        "Lykon/dreamshaper-6",
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        safety_checker=None,
        use_safetensors=True
    )
    return pipe.to(device)

@st.cache_resource(show_spinner=False)
def load_yolov5_model():
    """YOLOv5ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    # torch.hub.loadã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    # ultralytics/yolov5ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰'yolov5s'ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
    return model

# YOLOv5ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œå‡ºã™ã‚‹é–¢æ•°
def detect_objects_yolov5(model, image_path):
    """YOLOv5ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ç”»åƒå†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œå‡ºã—ã€æ•°ã‚’è¿”ã™"""
    results = model(image_path)
    # æ¤œå‡ºçµæœã‚’pandas DataFrameã¨ã—ã¦å–å¾—ã—ã€æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ•°ã‚’è¿”ã™
    df = results.pandas().xyxy[0]
    return len(df)

# --- Streamlitã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚’é¸æŠ
screen = st.sidebar.selectbox("ãƒ¢ãƒ¼ãƒ‰é¸æŠ", ["æ•°å½“ã¦", "æ‰‹è©±", "æ•°å½“ã¦ver0.0.1"])

# --- æ•°å½“ã¦ãƒ¢ãƒ¼ãƒ‰ ---
if screen == "æ•°å½“ã¦":
    st.title("ğŸ æœç‰©å½“ã¦ã‚²ãƒ¼ãƒ ï¼ˆç‰©ä½“æ¤œçŸ¥ã§æ­£è§£ã‚’è‡ªå‹•åˆ¤å®šï¼‰ğŸŠ")
    st.write("ç”»åƒã«æ˜ ã‚‹æœç‰©ã®æ•°ã‚’äºˆæƒ³ã—ã¦ã­ï¼ï¼ˆç­”ãˆã¯1ã€œ10ã®ç¯„å›²ã§ã™ï¼‰")

    # åˆæœŸåŒ–
    fruit_options = ["ã‚Šã‚“ã”", "ã¿ã‹ã‚“"]
    if "fruit" not in st.session_state:
        st.session_state.fruit = random.choice(fruit_options)
        st.session_state.image_path = None
        st.session_state.generated = False
        st.session_state.result_shown = False
        st.session_state.guess = None # äºˆæƒ³æ•°ã‚’åˆæœŸåŒ–

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€st.cache_resourceã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹
    pipe = load_diffusion_model()
    yolo_model = load_yolov5_model()

    # ç”»åƒç”Ÿæˆ
    if not st.session_state.generated:
        fruit = st.session_state.fruit
        eng = "red apples" if fruit == "ã‚Šã‚“ã”" else "oranges"

        while True:
            num = random.randint(1, 10)
            st.session_state.num = num

            prompt = (
                f"A high-resolution, realistic photo showing exactly {num} whole, clearly visible, and similarly sized {eng}, "
                "all fully in frame and evenly distributed on a clean white tabletop. No overlapping. "
                "Each fruit should be around palm-sized and spaced apart. Shot with soft, natural lighting, ultra-detailed, 4k quality."
            )

            with st.spinner(f"ç”»åƒã‚’ç”Ÿæˆä¸­... (CPUç’°å¢ƒã®ãŸã‚æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"):
                image = pipe(prompt, height=512, width=512, num_inference_steps=30).images[0]

            save_path = "generated_fruit.png"
            image.save(save_path)
            st.session_state.image_path = save_path

            # ç”Ÿæˆã•ã‚ŒãŸç”»åƒã§ç‰©ä½“æ¤œå‡ºã‚’è¡Œã„ã€æ¤œå‡ºã•ã‚ŒãŸæ•°ã‚’å–å¾—
            detected = detect_objects_yolov5(yolo_model, save_path)

            # æ¤œå‡ºæ•°ãŒ10å€‹ä»¥ä¸‹ã§ã‚ã‚Œã°OKã€ãã†ã§ãªã‘ã‚Œã°å†ç”Ÿæˆ
            if detected <= 10:
                st.session_state.detected_count = detected
                break
            else:
                st.warning(f"âš ï¸ {detected}å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ç›®æ¨™ã®10å€‹ã‚’è¶…ãˆãŸãŸã‚ã€ç”»åƒã‚’å†ç”Ÿæˆã—ã¾ã™...")

        st.session_state.generated = True

    # ç”»åƒè¡¨ç¤º
    if st.session_state.image_path and os.path.exists(st.session_state.image_path):
        st.image(st.session_state.image_path, caption="ã“ã®ä¸­ã«ä½•å€‹ã‚ã‚‹ï¼Ÿ", use_container_width=True)
    else:
        st.warning("ç”»åƒãŒã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # ã‚«ãƒ¡ãƒ©ã§æŒ‡ã®æ•°ã‚’å…¥åŠ›ï¼ˆäºˆæƒ³ï¼‰
    st.info("ãƒ’ãƒ³ãƒˆï¼šæœç‰©ã®æ•°ã¯ 1ã€œ10 ã®é–“ã§ã™ã€‚")
    st.write("ã„ãã¤ã‚ã‚‹ã¨æ€ã„ã¾ã™ã‹ï¼Ÿï¼ˆæŒ‡ã§å…¥åŠ›ï¼‰")
    
    # camera()é–¢æ•°ã¯ã€æŒ‡ã®æ•°ã‚’æ¤œå‡ºã—ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ãã®æ•°ã‚’è¿”ã™
    current_guess = camera()
    if current_guess is not None:
        st.session_state.guess = current_guess # æ¤œå‡ºã•ã‚ŒãŸæŒ‡ã®æ•°ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
        st.write(f'ã‚ãªãŸã®äºˆæƒ³: {st.session_state.guess} å€‹')

    # ç­”ãˆåˆã‚ã›ãƒœã‚¿ãƒ³
    if st.button("ç­”ãˆåˆã‚ã›"):
        if st.session_state.guess is None:
            st.warning("ã¾ãšæŒ‡ã‚’ä½¿ã£ã¦æœç‰©ã®æ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            answer = st.session_state.detected_count # YOLOv5ã§æ¤œå‡ºã•ã‚ŒãŸå®Ÿéš›ã®æ•°
            guess = st.session_state.guess # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡ã§å…¥åŠ›ã—ãŸäºˆæƒ³æ•°
            fruit = st.session_state.fruit
            
            if guess == answer:
                st.success(f"ğŸ‰ æ­£è§£ï¼{fruit}ã¯ {answer} å€‹ã‚ã‚Šã¾ã—ãŸï¼")
            else:
                st.error(f"ğŸ˜¢ æ®‹å¿µï¼æ­£è§£ã¯ {answer} å€‹ã® {fruit} ã§ã—ãŸã€‚")
            
            # ç”Ÿæˆæ™‚ã®ç›®æ¨™æ•°ã‚‚è¡¨ç¤ºï¼ˆæ¤œå‡ºæ•°ã¨ç•°ãªã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ï¼‰
            st.info(f'å®Ÿéš›ã¯{fruit}ã‚’{st.session_state.num}å€‹ã§ç”Ÿæˆã—ãŸç”»åƒã§ã™')
            st.session_state.result_shown = True # çµæœãŒè¡¨ç¤ºã•ã‚ŒãŸã“ã¨ã‚’è¨˜éŒ²

    # ã‚‚ã†ä¸€åº¦éŠã¶ãƒœã‚¿ãƒ³
    if st.session_state.result_shown:
        if st.button("ã‚‚ã†ä¸€åº¦éŠã¶"):
            st.session_state.clear() # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‚²ãƒ¼ãƒ ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.rerun() # ã‚¢ãƒ—ãƒªã‚’å†å®Ÿè¡Œ

# --- æ‰‹è©±ãƒ¢ãƒ¼ãƒ‰ ---
elif screen == "æ‰‹è©±":
    st.title("âœ‹ æŒ‡ã®æœ¬æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦æŒ¨æ‹¶ã‚¯ã‚¤ã‚º")

    # MediapipeåˆæœŸåŒ– (æ‰‹è©±ãƒ¢ãƒ¼ãƒ‰ç”¨ã«åˆ¥é€”åˆæœŸåŒ–)
    # static_image_mode=False ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’æƒ³å®š
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)

    # æŒ‡ã®æœ¬æ•°ã‚’æ•°ãˆã‚‹é–¢æ•° (æ‰‹è©±ãƒ¢ãƒ¼ãƒ‰ç”¨)
    def count_fingers(hand_landmarks):
        finger_count = 0
        landmarks = hand_landmarks.landmark

        # äººå·®ã—æŒ‡ã‹ã‚‰å°æŒ‡ã¾ã§ã®å…ˆç«¯ã¨PIPé–¢ç¯€ã®Yåº§æ¨™ã‚’æ¯”è¼ƒ
        tips = [8, 12, 16, 20] # å„æŒ‡ã®å…ˆç«¯ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ID
        pips = [6, 10, 14, 18] # å„æŒ‡ã®PIPé–¢ç¯€ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ID
        for tip, pip in zip(tips, pips):
            if landmarks[tip].y < landmarks[pip].y: # æŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ã‹
                finger_count += 1

        # è¦ªæŒ‡ï¼ˆå³æ‰‹åŸºæº–ã§ã€å…ˆç«¯ãŒä»˜ã‘æ ¹ã‚ˆã‚Šå·¦ã«ã‚ã‚‹ã‹ã§åˆ¤æ–­ï¼‰
        # å·¦æ‰‹ã®å ´åˆã¯Xåº§æ¨™ã®æ¯”è¼ƒãŒé€†ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã‚ˆã‚Šæ±ç”¨çš„ãªè§’åº¦è¨ˆç®—ã®æ–¹ãŒè‰¯ã„å ´åˆã‚‚ã‚ã‚‹
        # ä»Šå›ã¯ç°¡æ˜“çš„ã«Xåº§æ¨™ã§åˆ¤æ–­
        if landmarks[4].x < landmarks[3].x: # è¦ªæŒ‡ã®å…ˆç«¯ãŒä»˜ã‘æ ¹ã‚ˆã‚Šå·¦ã«ã‚ã‚‹ï¼ˆè¦ªæŒ‡ãŒä¼¸ã³ã¦ã„ã‚‹ï¼‰
            finger_count += 1

        return finger_count

    # æŒ‡ã®æœ¬æ•°ã§æŒ¨æ‹¶ã‚’åˆ†é¡ã™ã‚‹é–¢æ•°
    def classify_greeting(count):
        if count == 1:
            return "ã“ã‚“ã«ã¡ã¯"
        elif count == 5:
            return "ã‚ã‚ŠãŒã¨ã†"
        elif count == 0:
            return "ãƒã‚¤ãƒã‚¤"
        else:
            return "èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ"

    # ãƒ“ãƒ‡ã‚ªå‡¦ç†ã‚¯ãƒ©ã‚¹ (streamlit-webrtcç”¨)
    class HandShot(VideoTransformerBase):
        def __init__(self):
            self.frame = None
            self.mp_hands = mp.solutions.hands
            self.hands = self.mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)
            self.mp_drawing = mp.solutions.drawing_utils

        def transform(self, frame):
            img = frame.to_ndarray(format="bgr24")
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            results = self.hands.process(img_rgb)

            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    self.mp_drawing.draw_landmarks(img, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)
                    
                    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æŒ‡ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã€ç”»é¢ã«è¡¨ç¤ºã™ã‚‹ã“ã¨ã‚‚å¯èƒ½
                    # count = count_fingers(hand_landmarks)
                    # greeting = classify_greeting(count)
                    # cv2.putText(img, f"Fingers: {count} ({greeting})", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
            
            self.frame = img # æœ€æ–°ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜
            return img

    # webrtc_streamerã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
    ctx = webrtc_streamer(
        key="finger-count-webrtc", # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚­ãƒ¼
        video_processor_factory=HandShot,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

    # æ’®å½±çµæœã¨ã‚¯ã‚¤ã‚ºã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    captured_image_placeholder = st.empty()
    result_placeholder = st.empty()

    # æ’®å½±ãƒœã‚¿ãƒ³
    if st.button("ğŸ“¸ æ’®å½±ã—ã¦æŒ‡ã®æœ¬æ•°ã‚’èªè­˜ã—ã‚¯ã‚¤ã‚ºé–‹å§‹"):
        if ctx.video_processor and ctx.video_processor.frame is not None:
            image = ctx.video_processor.frame.copy() # æœ€æ–°ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = hands.process(rgb) # é™æ­¢ç”»ã¨ã—ã¦å‡¦ç†

            if results.multi_hand_landmarks:
                hand_landmarks = results.multi_hand_landmarks[0]
                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                count = count_fingers(hand_landmarks)
                greeting = classify_greeting(count)

                # æ’®å½±çµæœç”»åƒã‚’è¡¨ç¤º
                captured_image_placeholder.image(image, caption="æ’®å½±çµæœ", channels="BGR", use_container_width=True)

                # ã‚¯ã‚¤ã‚ºå•é¡Œã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.quiz_greeting = greeting
                st.session_state.quiz_answered = False

                result_placeholder.info("ã‚¯ã‚¤ã‚ºé–‹å§‹ï¼ã“ã®æ‰‹è©±ã¯ä½•ã®æŒ¨æ‹¶ã§ã—ã‚‡ã†ã‹ï¼Ÿ ä¸‹ã®å…¥åŠ›æ¬„ã«ç­”ãˆã¦ãã ã•ã„ã€‚")

            else:
                result_placeholder.warning("æ‰‹ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦æ’®å½±ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.error("ç”»åƒãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # ã‚¯ã‚¤ã‚ºå›ç­”å…¥åŠ›æ¬„
    if "quiz_greeting" in st.session_state and not st.session_state.get("quiz_answered", False):
        user_input = st.text_input("æŒ¨æ‹¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã“ã‚“ã«ã¡ã¯ã€ã‚ã‚ŠãŒã¨ã†ã€ãƒã‚¤ãƒã‚¤ï¼‰")

        if st.button("å›ç­”ã™ã‚‹"):
            correct_answer = st.session_state.quiz_greeting
            if user_input == correct_answer:
                result_placeholder.success(f"æ­£è§£ï¼ã“ã®æ‰‹è©±ã¯ã€Œ{correct_answer}ã€ã§ã™ã€‚")
            else:
                result_placeholder.error(f"ä¸æ­£è§£ï¼æ­£è§£ã¯ã€Œ{correct_answer}ã€ã§ã™ã€‚")

            st.session_state.quiz_answered = True
            # å›ç­”å¾Œã€ã‚‚ã†ä¸€åº¦æ’®å½±ãƒœã‚¿ãƒ³ã§ãƒªãƒˆãƒ©ã‚¤ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹

# --- æ•°å½“ã¦ver0.0.1 ãƒ¢ãƒ¼ãƒ‰ ---
elif screen == "æ•°å½“ã¦ver0.0.1":
    st.title("æœç‰©å½“ã¦ã‚²ãƒ¼ãƒ  ver0.0.1")
    st.write("ç”»åƒã«æ˜ ã‚‹æœç‰©ã®æ•°ã‚’äºˆæƒ³ã—ã¦ã­ï¼ï¼ˆç­”ãˆã¯1ã€œ10ã®ç¯„å›²ã§ã™ï¼‰")

    # é€£ç¶šæ­£è§£è¨˜éŒ²ã®åˆæœŸåŒ–
    if "v001_consecutive_streak" not in st.session_state:
        st.session_state.v001_consecutive_streak = 0
    st.write(f"é€£ç¶šæ­£è§£è¨˜éŒ²: **{st.session_state.v001_consecutive_streak}** å›")

    # ã‚²ãƒ¼ãƒ çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆåˆå›ã¾ãŸã¯ã€Œã‚‚ã†ä¸€åº¦éŠã¶ã€æ™‚ï¼‰
    if "v001_generated" not in st.session_state or not st.session_state.v001_generated:
        # v001_consecutive_streak ä»¥å¤–ã‚’ãƒªã‚»ãƒƒãƒˆ
        temp_streak = st.session_state.v001_consecutive_streak
        reset_game_state()
        st.session_state.v001_consecutive_streak = temp_streak
        
        st.session_state.v001_fruit = random.choice(["ã‚Šã‚“ã”", "ã¿ã‹ã‚“"])
        fruit = st.session_state.v001_fruit
        eng = "red apples" if fruit == "ã‚Šã‚“ã”" else "oranges"

        while True:
            num = random.randint(1, 10)
            st.session_state.v001_num = num

            prompt = (
                f"A high-resolution, realistic photo showing exactly {num} whole, clearly visible, and similarly sized {eng}, "
                "all fully in frame and evenly distributed on a clean white tabletop. No overlapping. "
                "Each fruit should be around palm-sized and spaced apart. Shot with soft, natural lighting, ultra-detailed, 4k quality."
            )

            with st.spinner("ç”»åƒã‚’ç”Ÿæˆä¸­... (CPUç’°å¢ƒã®ãŸã‚æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"):
                image = pipe(prompt, height=512, width=512, num_inference_steps=30).images[0]

            save_path = "generated_fruit.png"
            image.save(save_path)
            st.session_state.v001_image_path = save_path

            detected = detect_objects_yolov5(yolo_model, save_path)

            if detected <= 10:
                st.session_state.v001_detected_count = detected
                break
            else:
                st.warning(f"âš ï¸ {detected}å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ç›®æ¨™ã®10å€‹ã‚’è¶…ãˆãŸãŸã‚ã€ç”»åƒã‚’å†ç”Ÿæˆã—ã¾ã™...")

        st.session_state.v001_generated = True
        st.rerun() # ç”»åƒç”Ÿæˆå¾Œã«å†å®Ÿè¡Œã—ã¦ç”»åƒã‚’è¡¨ç¤º

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ (åˆå›ã®ã¿ãƒ­ãƒ¼ãƒ‰)
    pipe = load_diffusion_model()
    yolo_model = load_yolov5_model()

    if st.session_state.get("v001_image_path") and os.path.exists(st.session_state.v001_image_path):
        st.image(st.session_state.v001_image_path, caption="ã“ã®ä¸­ã«ä½•å€‹ã‚ã‚‹ï¼Ÿ", use_container_width=True)

    st.info("ãƒ’ãƒ³ãƒˆï¼šæœç‰©ã®æ•°ã¯ 1ã€œ10 ã®é–“ã§ã™ã€‚")
    st.write("ã„ãã¤ã‚ã‚‹ã¨æ€ã„ã¾ã™ã‹ï¼Ÿï¼ˆæŒ‡ã§å…¥åŠ› - 2æšã®å†™çœŸã‚’æ’®ã£ã¦åˆè¨ˆã—ã¾ã™ï¼‰")

    # MediaPipeã®åˆæœŸåŒ–
    mp_hands, mp_drawing, hands = mediapipe_reset()

    # 1æšç›®ã®å†™çœŸ
    if not st.session_state.get("v001_photo1_taken", False):
        st.subheader("ğŸ“¸ 1æšç›®ã®å†™çœŸã‚’æ’®ã£ã¦ãã ã•ã„")
        uploaded_file1 = camera_input_widget("1æšç›®ã®å†™çœŸ", key="v001_camera1_input")
        if uploaded_file1 is not None:
            # mediapipe_process é–¢æ•°ã§ç”»åƒå‡¦ç†ã¨è¡¨ç¤ºã‚’è¡Œã†
            count1 = mediapipe_prosess(uploaded_file1, mp_hands, mp_drawing, hands)
            st.session_state.v001_camera1_count = count1
            st.success(f"1æšç›®ã§{count1}æœ¬ã®æŒ‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            if st.button("âœ… æ¬¡ã¸", key="v001_confirm_photo1"):
                st.session_state.v001_photo1_taken = True
                st.rerun()
    else:
        st.info(f"1æšç›®ã®æŒ‡ã®æ•°: {st.session_state.v001_camera1_count}æœ¬ (ç¢ºå®šæ¸ˆã¿)")

    # 2æšç›®ã®å†™çœŸ
    if st.session_state.get("v001_photo1_taken") and not st.session_state.get("v001_photo2_taken"):
        st.subheader("ğŸ“¸ 2æšç›®ã®å†™çœŸã‚’æ’®ã£ã¦ãã ã•ã„")
        uploaded_file2 = camera_input_widget("2æšç›®ã®å†™çœŸ", key="v001_camera2_input")
        if uploaded_file2 is not None:
            count2 = mediapipe_prosess(uploaded_file2, mp_hands, mp_drawing, hands)
            st.session_state.v001_camera2_count = count2
            st.success(f"2æšç›®ã§{count2}æœ¬ã®æŒ‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            if st.button("âœ… çµæœã‚’è¦‹ã‚‹", key="v001_confirm_photo2"):
                st.session_state.v001_photo2_taken = True
                st.session_state.v001_guess = st.session_state.v001_camera1_count + st.session_state.v001_camera2_count
                st.success(f"åˆè¨ˆã®äºˆæƒ³: {st.session_state.v001_guess} å€‹")
                st.rerun()
    elif st.session_state.get("v001_photo1_taken") and st.session_state.get("v001_photo2_taken"):
        st.info(f"2æšç›®ã®æŒ‡ã®æ•°: {st.session_state.v001_camera2_count}æœ¬ (ç¢ºå®šæ¸ˆã¿)")
        st.success(f"åˆè¨ˆã®äºˆæƒ³: {st.session_state.v001_guess} å€‹")

    # ç­”ãˆåˆã‚ã›
    if st.session_state.get("v001_photo1_taken") and st.session_state.get("v001_photo2_taken") and st.session_state.get("v001_guess") is not None:
        if not st.session_state.get("v001_answer_checked", False):
            if st.button("ç­”ãˆåˆã‚ã›", key="v001_check_answer"):
                answer = st.session_state.v001_detected_count
                guess = st.session_state.v001_guess
                fruit = st.session_state.v001_fruit

                if guess == answer:
                    st.session_state.last_result_message = f"ğŸ‰ æ­£è§£ï¼{fruit}ã¯ {answer} å€‹ã§ã—ãŸï¼"
                    st.session_state.last_result_type = "success"
                    st.session_state.v001_consecutive_streak += 1
                else:
                    st.session_state.last_result_message = f"ğŸ˜¢ æ®‹å¿µï¼æ­£è§£ã¯ {answer} å€‹ã® {fruit} ã§ã—ãŸã€‚"
                    st.session_state.last_result_type = "error"
                    st.session_state.v001_consecutive_streak = 0 # ä¸æ­£è§£ã§é€£ç¶šè¨˜éŒ²ã‚’ãƒªã‚»ãƒƒãƒˆ

                st.session_state.last_actual_num_message = f'å®Ÿéš›ã¯{fruit}ã‚’{st.session_state.v001_num}å€‹ã§ç”Ÿæˆã—ã¾ã—ãŸ'
                st.session_state.v001_result_shown = True
                st.session_state.v001_answer_checked = True
                st.rerun() # çµæœè¡¨ç¤ºã®ãŸã‚ã«å†å®Ÿè¡Œ
        else:
            st.info("ç­”ãˆåˆã‚ã›ã¯å®Œäº†ã—ã¦ã„ã¾ã™ã€‚")

    # çµæœè¡¨ç¤ºã¨ã€Œã‚‚ã†ä¸€åº¦éŠã¶ã€ãƒœã‚¿ãƒ³
    if st.session_state.get("v001_result_shown"):
        if st.session_state.last_result_type == "success":
            st.success(st.session_state.last_result_message)
        else:
            st.error(st.session_state.last_result_message)
        st.info(st.session_state.last_actual_num_message)
        st.write(f"ç¾åœ¨ã®é€£ç¶šæ­£è§£è¨˜éŒ²: {st.session_state.v001_consecutive_streak} å›")

        if st.button("ã‚‚ã†ä¸€åº¦éŠã¶", key="v001_play_again"):
            # é€£ç¶šè¨˜éŒ²ä»¥å¤–ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦å†å®Ÿè¡Œ
            temp_streak = st.session_state.v001_consecutive_streak
            reset_game_state()
            st.session_state.v001_consecutive_streak = temp_streak
            st.rerun()

